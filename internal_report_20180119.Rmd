---
title: "Initial NSDC Analysis - Updated"
author: "Greg Lane and Erin Kelley"
date: "January 19, 2018"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r echo=F, message=FALSE, warning=FALSE, messages=F, paged.print=FALSE}
rm(list = ls())
options(stringsAsFactors = FALSE)

library(tidyverse)
library(magrittr)
library(foreign)
library(readxl)
library(lubridate) 
library(ggplot2)
library(lfe)

if(Sys.info()["user"] == "erinmkelley") {
  setwd("~/Dropbox/NSDC/Data Acquisition/sample")
  data <- read_excel("20171129_Sep2016Aug2017.xlsx") 
}

if(Sys.info()["user"] == "gregorylane") {
  setwd("~/Dropbox/Berkeley/Research/NSDC/Data Acquisition/")
  data <- read_excel("sample/20171129_Sep2016Aug2017.xlsx") 
}


# clean data ----------------------------------------

names(data) %<>% tolower

#keep only vars that seem to be useful (for first pass)
workers <- data %>% select(candid, castecategory, educationattained, gender, grade, religion, 
               result, 'total theory marks', 'total practical marks', 
               totalmarkobtained, batchid, 'batch start date', 'batch end date',
               'assessment date', trainerid, trainergender, centreid,
               jobroleid, jobrole, jobrolelevel, jobroletype, 
               sectorid, sectorname, subsectorid, subsectorname, assessmentstatus,
               statecode, district, 'placement status', cerified, monthlyincome, yearofbirth)

#rename & clean-up
workers %<>% rename(id = candid,
               caste = castecategory,
               eduction = educationattained,
               theory_score = 'total theory marks',
               practical_score = 'total practical marks',
               total_score = totalmarkobtained,
               start_date = 'batch start date',
               end_date = 'batch end date',
               test_date ='assessment date',
               trainer_id = trainerid,
               trainer_gender = trainergender,
               center_id = centreid,
               job_id = jobroleid,
               job_level = jobrolelevel,
               job_type = jobroletype,
               placement = 'placement status',
               certified = cerified) %>%
    
  mutate(STOBC = caste %in% c('ST', 'OBC'),
         male = gender == 'Male',
         grade = gsub(grade ,pattern="Grade ", replacement=""),
         hindu = religion=="Hinduism",
         passed = result=="Pass",
         start_date = as.POSIXct(start_date),
         end_date = as.POSIXct(end_date),
         test_date = as.POSIXct(test_date),
         trainer_gender = trainer_gender == 'Male', #NOTE: there are transgender trainers, but keep binary for now
         placement = placement=="Yes",
         certified = certified=="Yes",
         monthlyincome = as.numeric(monthlyincome)) %>% #Note: need to fix education, but need years equivalents
  
  select(-c(caste, gender, religion, result))
 
  educ_mat <- as.data.frame(cbind(unique(as.character(workers$eduction)), 
                                  as.vector(c(10, 20, 18, 12, 8, 16, 12, 10, 4, 14)))) 
  #Note: need to fix education - need years equivalents of categories (these are guesses)
    
  workers %<>% merge(y = educ_mat, by.x = "eduction", by.y = "V1", all=TRUE) %>% 
     select(-eduction) %>% rename(years_educ = V2) %>% mutate(years_educ = as.numeric(years_educ)) 
```

## Distribution of Test Scores

A candidates final score is comprised of a score on a theory section and one on a practical section which are added together. In order to receive a certificate from a training institude, students enrolled in a program for a "Level 3" job (generally less skilled) must receive 50% of the total points, while those enrolled in a "Level 4" training require 70%. Below we plot the total score, the practical score, and the theory score for trainees in the Beauty Salon Program (Level 3). In each graph we plot the scores for the certified versus non-certified students. The certification threshold is clearly visible on the graph depicting total scores. 


```{r, echo = F, messages = F, results='hide', fig.keep='all'}
  #sectors - and job_level are going to determine certification.  
  #for job level 3 need 50% to be certified, for job level 4 need 70% to be certified
  sector <- workers %>% group_by(sectorid, job_level, certified) %>%
    summarise(max_score = max(total_score),
              min_score = min(total_score),
              avg_score = mean(total_score),
              name = first(sectorname),
              count = n())

  #filter sectors that don't have many obs (<200)
  workers %<>% group_by(sectorid) %>% mutate(obs = n()) %>% filter(obs > 200)
  
  #function to plot score histograms by subsector & job level (3 or 4) & score type (total, theory, or practical)
  hister <- function(sector, DT, level, score) {
    data <- filter(DT, subsectorid==sector, job_level==level)
      sectorname = data$sectorname[1]
      subsectorname = data$subsectorname[1]
      if(sectorname!=subsectorname){sectorname <- paste(sectorname, '-' ,subsectorname)}
      sectorname = paste0(sectorname, '-', as.character(sector), " - Level " , as.character(level))
      plot_level_3 <- ggplot(data, aes_string(x = score, fill="certified")) + 
        geom_histogram(data =data %>% filter(total_score!=0) , binwidth = 5, alpha=0.4) + 
        ggtitle(paste(sectorname))
  }
  

  beauty <- 49
  lapply(beauty, FUN=hister, DT=workers, level=3, score="total_score")
  lapply(beauty, FUN=hister, DT=workers, level=3, score="theory_score")
  lapply(beauty, FUN=hister, DT=workers, level=3, score="practical_score")


```

A primary concern that we have that would violate the RD assumption is that testing agencies are manipulating scores (exacerbated by the fact that part of the payment from the NSDC is tied to the number of  trainees that achieve certification). One indication that this might be happening is the large spike in the distribution of scores in the practical score section. However, there are some institutional facts that suggest this may not be causing problems in the RD. 

Specifically, the theory section of the exam is conducted on a tablet with fixed questions and is automatically graded by a computer. The score on the theory section is not immediately reported to the trainee or testing agency. The practical exam is conducted and graded by the trainer and the score is inputted into the computer system. At that point, the theory and practical score are added together by the system to produce a total score. The trainee and training center are both informed about the overall results, including certification status. 

In this framework it would be particularly difficult for the testing agency to adjust the practical test scores such that trainees were able to pass the threshold for certification. They would have to know which students were going to fall just below and attribute them an additional few points on the practical section, which is unrealistic. Moreover, manipulation in this context would have to take the form of providing the students they favor with a great score on the practical section, which would simply shift the distribution of total scores to the right, leaving it smooth around the threshold, and satisfying the RD conditions. Finally, we were informed that you would expect the spikes you see in some of the score distributions because the exams are naturally modal (e.g. 10% of the exam is quite difficult while the other 90% is rather easy) and this isn't necessarily an indication of manipulation.

Note, there are some sectors where these justifications are less robust because the practical score makes up a very large percentage of the total score. In these cases a trainer could be nearly 100% certain that trainee will pass if they acheive a certain mark on the practical section. Therefore, they could simply take all the students right below the threshold and move them up. A possible example of this is paramedic training which is highly weighted towards the practical test.  

```{r, echo = F, messages = F}
  # graph parameidcs on own to adjust bins since scale is so different. 
 ggplot(workers %>% filter(subsectorid == 8, job_level==4, total_score!=0), 
        aes(x=total_score, fill=certified)) +
        geom_histogram(binwidth=30 ,alpha=0.4) + 
        ggtitle("Healthcare, Paramedics, Level 4 - Total Score")

 ggplot(workers %>% filter(subsectorid == 8, job_level==4, total_score!=0), 
        aes(x=practical_score, fill=certified)) +
        geom_histogram(binwidth=30 ,alpha=0.4) + 
        #geom_density(alpha=0.4) + 
        ggtitle("Healthcare, Paramedics, Level 4 - Practical Score")

  ggplot(workers %>% filter(subsectorid == 8, job_level==4, total_score!=0), 
        aes(x=theory_score, fill=certified)) +
        geom_histogram(binwidth=5 ,alpha=0.4) + 
        ggtitle("Healthcare, Paramedics, Level 4 - Theory Score")

```

We therefore restrict our analysis to sectors where the total score is not disproportionately determined by the practical scores. These sectors are IT, Telecom, Beauty, Tourism, Retail which together make up about half the sample. Next, we take a first pass at running the RD to see if being certified leads to increased employment and wages. (Note the data we were provided does not provide the total number of possible points on the exam, and so we need to infer the value of the threshold by looking at the minimum score that was attributed a certificate in the data. It looks like over time the minimum requirement may have changed which means this will be a fuzzy RD). The full sample distribution of test scores looks good across the threshold:    

```{r, echo = F, warning = F}
rd_data <- filter(workers, subsectorid %in% c(9, 68, 14, 13, 49))

#grab min qualifying score as threshold - assume that non-certified above that threshold didn't pass for other reason
#this is big assumption, which we should check with NSDC

rd_data <- left_join(rd_data, 
                     rd_data %>% group_by(subsectorid, certified) %>%
      summarise(threshold = min(total_score)) %>% ungroup() %>%
      filter(certified==TRUE) %>% select(-certified),
    by = 'subsectorid') %>%
  
  mutate(running = total_score - threshold, above = running > 0, above_run = above * running)

#plot combined distribution of running variable around threshold - this looks okay
ggplot(rd_data %>% filter(total_score!=0), aes(x = running)) + 
  geom_histogram(binwidth = 5, alpha=0.6) + 
  geom_vline(xintercept=0, colour="gray") +
  ggtitle('Combined Centered Scores') +
  xlab("Centered Test Score")
```

## Outcome Data and RD

There are two outcomes of interest for which we have data from the NSDC: 1) The probability of being employed within one month of the program's end and 2) reported monthly income conditional on employment. These data are collected by the training centers themselves, and part of their compensation is tied to the number of trainees they place in jobs within two months of the end of training. The NSDC tries to ensure these jobs are real by requiring that pay stubs be submitted before the center is rewarded for the job placement. However, there is ancetodal evidence that these jobs tend to last for a very short time period and so any results will likely reflect a very short run outcome rather than sustained gains from becoming certified.  

Below are two graphs that visually represent the RD on these two outcomes. Visually, there appears to be positive increases both in the probability of being employed and in the monthly wages earned by trainees at the certification threshold. The third graph shows smoothness in reported years of education across the threshold (education is the only observable we have on trainees).

```{r, echo = F, warning = F}
  col_rd_data <- rd_data %>% group_by(above) %>% mutate(bin = ntile(running, 10)) %>% 
    ungroup() %>% group_by(above, bin) %>% 
    summarise(monthlyincome = mean(monthlyincome, na.rm=TRUE),
              placement = mean(placement),
              running= mean(running, na.rm=TRUE),
              years_educ = mean(years_educ, na.rm=TRUE)) 
  

  #plot outcome vars across threshold - remember, this is fuzzy RD
  ggplot(rd_data %>% filter(total_score!=0), aes(x = running, y=as.numeric(placement), colour = above)) + 
    geom_point(data=col_rd_data) +
    geom_smooth(method=loess) +
    geom_vline(xintercept = 0, colour = "gray") +
    xlim(-200,200) +
    xlab('Centered Test Score') + ylab('Likelihood Employed') +
    scale_colour_manual(name="Certified", values=c("#F8766D", "#00BFC4"))
    #these are the default ggplot colors, but I had to manually input the to change the legend
  
  ggplot(rd_data %>% filter(total_score!=0), aes(x = running, y=monthlyincome, colour = above)) + 
    geom_point(data=col_rd_data) +
    geom_smooth(method = loess) +
    geom_vline(xintercept = 0, colour = "gray") +
    xlim(-200,200) +
    xlab('Centered Test Score') + ylab('Monthly Income (Rupees)') +
    scale_colour_manual(name="Certified", values=c("#F8766D", "#00BFC4")) 
  
    #placebo rd - looks good for education (the only X we really have)
  ggplot(rd_data %>% filter(total_score!=0), aes(x = running, y = years_educ, colour = as.character(above))) + 
    geom_point(data=col_rd_data) +
    geom_smooth(method=lm, formula = y ~ splines::bs(x, 3)) +
    geom_vline(xintercept = 0, colour = "gray") +
    xlim(-200,200) +
    xlab('Centered Test Score') + ylab('Years Educ (Placebo)') +
    scale_colour_manual(name="Certified", values=c("#F8766D", "#00BFC4"))
```

## Regressions

We can also run this analysis via regression (no attempt at bandwidth yet): 

```{r, echo = T, warning = F}
rd_data %<>% mutate(above = as.numeric(above), placement = as.numeric(placement)) %>%
  rename(above_threshold = above, test_score = running, test_X_above = above_run ) 
  

#simple rd regs 
felm(placement ~ above_threshold + test_score + test_X_above | 
       subsectorid + trainer_id | 0 | center_id, data = rd_data) %>% 
  summary()
felm(monthlyincome ~ above_threshold + test_score + test_X_above | 
       subsectorid + trainer_id | 0 | center_id, data = rd_data) %>% 
  summary()
```

The points estimates above show being certified increases the probability of being employed by 22 percentage points and increases monthly income (conditional on being employed) by 450 rupees. 

## Summary and Ideas Moving Forward

In general, I think the identification strategy is okay. The particulars of the certification process would make it hard to manipulate the score to the precision necessary to mess up the RD. However, the outcomes we can currently measure are not probably the outcomes we care most about in evaluating the program.  

Therefore, we can try and get more data on medium run outcomes by:

1. Asking NSDC if they would be willing to collect this data themselves. Could take a long time, but wouldn't require asking for grant money. 

2. Collect data ourselves using exisiting database of phone numbers. Problems are that a) this will cost money (although likely not a ton), and b) the quality of the contact numbers isn't great. 

3. Partner more closely with certain well run training centers and collect good contact information, demographics, and then follow-up. This would require more money and time (and would probably have a smaller overall sample)  

We can also think about other ideas that we can examine with this data beyond just program evaluation. Just brainstorming:

1. Is there a difference between "practical" skills and "theoretical" skills in predicting job retention and wage? Does this vary across different sectors as we might expect? This might suggest that providing sub-scores is important

2. Value of certificate in different sectors? For some industries, a certificate might just be a signal of quality in terms of productivity to the employer. However, in some other setors (beauty), a certificate might also function as a measure of quality to the customer. Would be interesting to see if having a certificate was more important in these industries (controling for skill) than others.  

3. Examine selection into different trainings (there appears to be overall negative correlation between education and test score). If you are selecting the low performers of the educated crowd and the all-stars of the uneducated crowd could have interesting implications for signalling / hiring.

4. Examine performance at different training centers: are certain training centers are more effective than others?

5. Can we collect a more diverse set of outcomes? It may be that certification has no long run labor effects but helps women's empowerment for example. 

6. Any intention to do random audits?

7. If we can get a breakdown of the scores on various subcomponents of the test, we could see if employers value certain skills over others and therefore retain people longer? The breakdown of the theory section should be available through testing companies like AM, and if subscores are being entered for practical section there may be a way to get that data. 







