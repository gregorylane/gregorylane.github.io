?rowSums
##### Attemnpt to use Simulated Method of Moments to estimate model parameters (and check for model match)
# See notes from BU in literature folder for example
# Basic approach: 1.) Solve model and create function that simulates data / outcomes for given vector of parameters,
#                 2.) Create estimator that chooses parameters that weighted minimize distance between actual moments
#                 in data and the simulated moments from the model output.
#                     - Optimal weight is related to inverst-variance of the moment in the actual data
#
# Thoughts on parameters to estimate and moments to match:
# - Target, profit, and salary are deterministic with one another, so match all three, but won't be able to match perfectly
# - U and probability of separation are only other moments to match in status quo. So we can play around with three parameters (I think)
# - Inputs (parameters): repair cost-we observe (fix), work cost (estimate), firing cost (estimate)
#         discount factor (fix), outside option (estimate)
# - Identification for 3 unknown model parameters thoughts: firing cost identified by separation prob,
#       outside option pinned down by value to keep job question,
#       work cost pinned down by target, salary, and profit (these three things are jointly determined)
#Note on over-id test for SMM - can nominally use the loss function output (J) and compare to chi-squared
# J * S/(S+T) ~ X(N_moments - N_parameters) - so here, we have 5 moments, and three parameters, so crit value = 5.99
# Not clear wahat S and T are. I think it's the simulation obs (S) and the actual obs (T), so here we have equal number I think,
# so 0.5*J ~ X_(5-3)
# latest estimation: J = 3.12  , 0.5*3.12 = 1.56, X_(5-3),   pchisq(1.56, df=2) gives p-value
rm(list = ls())
options(stringsAsFactors=FALSE)
library(pacman)
p_load(data.table, tidyverse, magrittr, ggplot2, FixedPoint, fitdistrplus, stats, boot,
stargazer, xtable, lfe, huxtable, dfoptim)
?hjkb
sessionInfo()
?geom_smooth
??geom_smooth
sink("genderbias_code_replication.txt")
# LOAD PACKAGES-----
library(pacman)
p_load(
readxl, data.table, dplyr, tidyverse, viridis, scales, knitr, kableExtra,
tidytext, tm, sentimentr, magrittr, googleLanguageR,
chron, textstem, cld2, countrycode
)
# SET PATH -----
if(Sys.info()["user"] == "boruis"){
root <- "C:/Users/sunsh/Dropbox/GenderBiases/Code/replication/"
}
if(Sys.info()["user"] == "erinmkelley") {
root <- "~/Dropbox/Jumia/GenderBiases/Code/replication/"
}
if(Sys.info()["user"] == "laneg") {
root <- "~/Dropbox/Projects/GenderBiases/Code/replication/"
}
# Chat data
chats_expand <- fread(paste0(path_intdata, "chats_expand_20190101_20191231_en_senti.csv"), encoding = "UTF-8")
# Data path
path_rawdata <- paste0(root, "data/1_Raw/")
path_intdata <- paste0(root, "data/2_Intermediate/")
path_findata <- paste0(root, "data/3_Final/")
# Chat data
chats_expand <- fread(paste0(path_intdata, "chats_expand_20190101_20191231_en_senti.csv"), encoding = "UTF-8")
chats_sentiment <- fread(paste0(path_intdata, "chats_sentiment_20190101_20191231_jockers.csv"), encoding = "UTF-8")
chats <- paste0(path_rawdata, "/chats/Salesforce/with_IP/pull_2021") %>%
list.files(full.names = TRUE, pattern = ".xlsx$") %>%
map(~read_excel(., na = "-", col_types = "text")) %>%
bind_rows()
# Randomization data
agents <- fread(paste0(path_rawdata, "randomization/treatment_assignment_alldates.csv"), encoding = "UTF-8")
# Sales data
sales <- read_excel(paste0(path_rawdata, "sales/shared/20190101_20191230_sales.xlsx"), sheet = "Sheet1")
# A. Address timezone offset issue =======
# remove chats with missing id
chats %<>% drop_na(`Chat Transcript ID`)
chats %<>% filter(Status == "Completed")
# remove duplicates
chats %<>% unique()
# Note: we conver all chat dates to UTC by using the timezone stamp in the chat body
#    or chat time + 1 during daylight saving time and chat time + 2 during standard time
chats$time <- gsub(".{,25}day,", "", chats$Body)
chats$time <- gsub("\\(.*", "", chats$time)
chats$time <- gsub("\\s*", "", chats$time)
chats$time <- chats$time %>% as.character() %>% as.POSIXct(format="%b%d,%Y,%H:%M:%S", tz = "UTC")
# now extract the timezone string
chats$timezone <- gsub(").*", "", chats$Body)
chats$timezone <- gsub(".*\\(", "", chats$timezone)
chats$timezone <- gsub("\\+0","", chats$timezone)
chats$timezone <- gsub("00$","", chats$timezone)
chats$timezone <- as.numeric(chats$timezone)
# now we subtract timezone diff from the time
chats$utc <- chats$time - chats$timezone*60*60
# we also bring in start time for comparison to check if conversion is correct
chats$`Start Time`<-  as.POSIXct(chats$`Start Time`, format = "%d/%m/%Y %H.%M", tz = "UTC") %>%
format("%d/%m/%y %H.%M") %>%
as.POSIXct(format = "%d/%m/%y %H.%M", tz = "UTC")
# the diff between utc and chat time should always be 1 during standard time and 2 during daylight saving time
chats$diff <- difftime(chats$`Start Time`, chats$utc, units = "hour")
chats$diff %>% round() %>% table()
chats %>% filter(diff == 1) %>% pull(time) %>% month() %>% unique()
chats %>% filter(diff == 2) %>% pull(time) %>% month() %>% unique()
# create merge key
chats %<>% mutate(ChatName = as.numeric(`Chat Transcript Name`))
# merge corrected utc back to chat data
chats_expand %<>% left_join(chats %>% select(ChatName, utc))
chats_expand$utc_end <- chats_expand$utc + 0.5*chats_expand$`Chat Duration`
# B. Merge with Agent to Get Agent's Assigned Gender ===========
# agent: create agent full name variable (to merge with chats data)
agents %<>% mutate(full_name = paste(agent_first, agent_last, sep = " "))
# convert dates to date format
agents$date        <- as.Date(agents$date)
chats_expand$date  <- as.Date(chats_expand$utc)
# merge chat with agent
chats_expand %<>% rename(full_name = `Created By: Full Name`)
chats_expand %<>% left_join(agents, by = c("full_name", "date"))
# C. Restrict Sample to Study Period =====
chats_expand %<>% filter(date < as.Date("2019-10-04"))
chats_expand %<>% mutate(weekend = ifelse(weekdays(date) %in% c("Sunday", "Saturday"), 1, 0))
temp <- chats_expand %>% filter(weekend == 0)
chats_expand %<>% filter(weekend == 0)
View(chats_expand)
View(chats)
chats$date <- as.Date(chats$utc)
chats %<>% filter(date < as.Date("2019-10-04"))
chats %<>% mutate(weekend = ifelse(weekdays(date) %in% c("Sunday", "Saturday"), 1, 0))
temp <- chats %>% filter(weekend == 0)
setwd("~/Dropbox/Mac/Documents/Website/gregorylane.github.io")
rmarkdown::render_site()
