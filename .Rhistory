#Re-Calc max target possible to limit search function
max_target2 = delta*U
V <-  (target - plogis(target, mean, std)*(1+(v_fix/U))*(target - exp_y_below) - exp_cost -
(1 - continue_prob)*delta*(v_fix-h))/(1 - delta) #Calc Value of contract for owner
#find target that maximizes the owner payoff given all the above
xmin <- qlogis(0.1, mean, std) #Note, for some parameter values, too low a target search leads to NAs which breaks system, change this if optim fails
xmax <- qlogis(0.6, mean, std)
own_payoff <- function(target, u) {
payoff <- delta*V + target - exp_cost - plogis(target, mean, std)*(1+h/U)*(target - exp_y_below)
#payoff <- delta*V + target - exp_cost - plogis(target, mean, std)*(1+h/U)*target + plogis(target, mean, std)*exp_y_below*(h/U)
}
tar <- optimize(own_payoff, interval=c(xmin, xmax), maximum=TRUE, u=U)$maximum
#Calculate owner payoff, driver payoff, and calc max target that driver will agree to (i.e. see if optimal owner target is outside of participation constraint)
own_payoff <- optimize(own_payoff, interval=c(xmin, max_target2), maximum=TRUE, u=U)$objective
dri_payoff <- delta*U - tar + mean - work_cost
min_agree_tar <- delta*U -dri_payoff + mean - work_cost
#Recalc target and payoffs now that see if at boundry
tar = min(tar, min_agree_tar)
own_payoff <- delta*V + tar - exp_cost - plogis(tar, mean, std)*(1+V/U)*(tar - exp_y_below)
profits <- tar - exp_cost - plogis(tar, mean, std)*(tar - exp_y_below)
exp_salary <- (1-plogis(target, mean, std))*(exp_y_above-target) + 7 #add back subsistence constraint
exp_income <- tar - plogis(tar, mean, std)*(tar - exp_y_below)
welfare <- U + V
return(c(tar, max_target2, U, V, continue_prob, profits, intercept, exp_salary, exp_income, welfare))
}
inputs <- c(g_target, 40, g_u, g_v, 0.9, 10, 0.9, 8, 10, g_welfare) #Give inputs for target, max target, Driver U, owner_payoff,  driver_payoff, and continue prob
values <- FixedPoint(Function = output, Inputs = inputs, Method = "Anderson", MaxIter = 10000)
end_target <- values$FixedPoint[1]
max_target_chosen <- round(values$FixedPoint[1],0.1) == round(values$FixedPoint[2], 0.1)
end_U <- values$FixedPoint[3]
end_V <- values$FixedPoint[4]
end_ep <- values$FixedPoint[5]
end_exp_profits <- values$FixedPoint[6]
end_intercept <- values$FixedPoint[7]
end_exp_salary <- values$FixedPoint[8]
end_exp_income <- values$FixedPoint[9]
end_welfare <- values$FixedPoint[10]
results <- c(end_target, end_U, end_V, end_ep, end_exp_profits, end_intercept, end_exp_salary, end_exp_income, end_welfare)
return(results)
}
#function to calc proportion lost income
lost_inc <- function(i) {
t <- 1:i
func <- function(x) {
val <- 10*0.99^(x-1)
}
vals <- lapply(t, func)
value <- 10 + sum(as.vector(unlist(vals)))
prop <- (10 + value)/(10/(1-0.99))
}
#Choose parameters
exp_cost <- 4.9 # in data average is 4.9 in control group, expected repairs costs at e* r* which are fixed by mean, std, of Y and independent of T, U
delta <- 0.99 #discount factor
work_cost <- 4 #  cost of effort + risk for driver which are independent of T, U - note: average G_e seems to be around 250, so seems reasonable that total cost is around that?
p <- lost_inc(60) #rehiring / firing cost for owner - input days lost income equivalent
outside_option <- 0/(1-delta) #"Value of job is 289.59" which should be U minus outside option?
#Bootstrap results
outputs <- as.data.frame(t(sapply(1:200, boot_opt, treat=0)) )
names(outputs) <- c("target", "U", "V", "ep", "exp_profit", "intercept", "exp_salary", "exp_income",  "welfare")
results<-data.frame(estimate=c(mean(outputs$target, na.rm=T), mean(outputs$U, na.rm=T), mean(outputs$V, na.rm=T), mean(outputs$ep, na.rm=T), mean(outputs$exp_profit, na.rm=T), mean(outputs$exp_salary, na.rm=T), mean(outputs$welfare, na.rm=T)),
stderr = c(sd(outputs$target, na.rm=T),sd(outputs$U, na.rm=T), sd(outputs$V, na.rm=T), sd(outputs$ep, na.rm=T), sd(outputs$exp_profit, na.rm=T), sd(outputs$exp_salary, na.rm=T), sd(outputs$welfare, na.rm=T)))
results$names <- c("target", "U", "V","ep","exp_profit", "exp_salary", "welfare")
#Put results into table for export
options(scipen=99)
table <- data.frame(Outcome = c("Target", "", "Expected Profit", "","Expected Salary", "", "Prob. Separation", "",
"Driver Contract Value minus Outside Option", "", "Owner Value", "",
"Total Welfare", ""),
Prediction=c(round(mean(outputs$target, na.rm=T), digits=2), paste0("(", as.character(round(sd(outputs$target, na.rm=T), digits=2)),")"),
round(mean(outputs$exp_profit, na.rm=T), digits=2), paste0("(", as.character(round(sd(outputs$exp_profit, na.rm=T), digits=2)),")"),
round(mean(outputs$exp_salary, na.rm=T), digits=2), paste0("(", as.character(round(sd(outputs$exp_salary, na.rm=T), digits=2)),")"),
round(1- mean(outputs$ep, na.rm=T), digits=4), paste0("(", as.character(round(sd(1-outputs$ep, na.rm=T), digits=5)),")"),
round(mean(outputs$U, na.rm=T)-outside_option, digits=2), paste0("(", as.character(round(sd(outputs$U, na.rm=T), digits=2)),")"),
round(mean(outputs$V, na.rm=T), digits=2), paste0("(", as.character(round(sd(outputs$V, na.rm=T), digits=2)),")"),
round(mean(outputs$welfare, na.rm=T), digits=2), paste0("(", as.character(round(sd(outputs$welfare, na.rm=T), digits=2)),")"))
)
#Notes: low outside option for driver lowers the target and increases change of firing
#High firing costs increasers the target, doesn't change much else
#Increasing work cost lower target - makese U, V lower, everyone worse off
##########
#Change parameters for comparison after monitoring (220 (ish) Ksh drop in repair costs, work time up 10ish percent, so move 1 more work cost given convexity?)
exp_cost <- 2.7 # in data, 490 in control group, expected repairs costs at e* r* which are fixed by mean, std, of Y and independent of T, U
delta <- 0.99 #discount factor
work_cost <- 5 # cost of effort + risk for driver which are independent of T, U - note: average G_e seems to be around 250, so seems reasonable that total cost is around that?
p <- lost_inc(60) #rehiring / firing cost for owner - input days lost income equivalent
outside_option <- 0/(1-delta) #"Value of job is 289.59" which should be U minus outside option?
outputs2 <- as.data.frame(t(sapply(1:200, boot_opt, treat=1)) )
names(outputs2) <- c("target", "U", "V", "ep", "exp_profit", "intercept", "exp_salary", "exp_income", "welfare")
results2<-data.frame(estimate=c(mean(outputs2$target, na.rm=T), mean(outputs2$U, na.rm=T), mean(outputs2$V, na.rm=T), mean(outputs2$ep, na.rm=T), mean(outputs2$exp_profit, na.rm=T), mean(outputs2$exp_salary, na.rm=T), mean(outputs2$welfare, na.rm=T)),
stderr = c(sd(outputs2$target, na.rm=T),sd(outputs2$U, na.rm=T), sd(outputs2$V, na.rm=T), sd(outputs2$ep, na.rm=T), sd(outputs2$exp_profit, na.rm=T), sd(outputs2$exp_salary, na.rm=T), sd(outputs2$welfare, na.rm=T)))
results2$names <- c("target", "U", "V","ep","exp_profit", "exp_salary", "welfare")
table2 <- data.frame(Outcome = c("Target", "", "Expected Profit", "","Expected Salary", "", "Prob. Separation", "",
"Driver Value", "", "Owner Value", "",
"Total Welfare", ""),
Prediction=c(round(mean(outputs2$target, na.rm=T), digits=2), paste0("(", as.character(round(sd(outputs2$target, na.rm=T), digits=2)),")"),
round(mean(outputs2$exp_profit, na.rm=T), digits=2), paste0("(", as.character(round(sd(outputs2$exp_profit, na.rm=T), digits=2)),")"),
round(mean(outputs2$exp_salary, na.rm=T), digits=2), paste0("(", as.character(round(sd(outputs2$exp_salary, na.rm=T), digits=2)),")"),
round(1-mean(outputs2$ep, na.rm=T), digits=4), paste0("(", as.character(round(sd(1-outputs2$ep, na.rm=T), digits=4)),")"),
round(mean(outputs2$U, na.rm=T)-outside_option, digits=2), paste0("(", as.character(round(sd(outputs2$U, na.rm=T), digits=2)),")"),
round(mean(outputs2$V, na.rm=T), digits=2), paste0("(", as.character(round(sd(outputs2$V, na.rm=T), digits=2)),")"),
round(mean(outputs2$welfare, na.rm=T), digits=2), paste0("(", as.character(round(sd(outputs2$welfare, na.rm=T), digits=2)),")"))
)
View(table)
View(table2)
?file
#Test to read .sql file for Matatu v_2
getSQL <- function(filepath){
con = file(filepath, "r")
sql.string <- ""
while (TRUE){
line <- readLines(con, n = 1)
if ( length(line) == 0 ){
break
}
line <- gsub("\\t", " ", line)
if(grepl("--",line) == TRUE){
line <- paste(sub("--","/*",line),"*/")
}
sql.string <- paste(sql.string, line)
}
close(con)
return(sql.string)
}
data <- getSQL("~/Dropbox/Matatu_v3/data/raw/sql2/pan_continuous.sql")
data <- getSQL("/Users/glane/Dropbox/Matatu_v3/data/raw/sql2/pan_continuous")
data <- readLines("/Users/glane/Dropbox/Matatu_v3/data/raw/sql2/pan_continuous")
data <- getSQL("/Users/glane/Dropbox/Matatu_v3/data/raw/sql2/pan_continuous/pan_continuous.sql")
#Test to read .sql file for Matatu v_2
getSQL <- function(filepath){
con = file(filepath, "r")
sql.string <- ""
while (TRUE){
line <- readLines(con, n = 1)
if ( length(line) == 0 ){
break
}
line <- gsub("\\t", " ", line)
if(grepl("--",line) == TRUE){
line <- paste(sub("--","/*",line),"*/")
}
sql.string <- paste(sql.string, line)
}
close(con)
return(sql.string)
}
data <- getSQL("/Users/glane/Dropbox/Matatu_v3/data/raw/sql2/pan_continuous/pan_continuous.sql")
getSQL <- function(filepath){
con = file(filepath, "r")
sql.string <- ""
while (TRUE){
line <- readLines(con, n = 1)
if ( length(line) == 0 ){
break
}
line <- gsub("\\t", " ", line)
if(grepl("--",line) == TRUE){
line <- paste(sub("--","/*",line),"*/")
}
sql.string <- paste(sql.string, line)
}
close(con)
return(sql.string)
}
data <- getSQL("/Users/glane/Dropbox/Matatu_v3/data/raw/sql2/pan_continuous/pan_continuous.sql")
data
data <- readLines("/Users/glane/Dropbox/Matatu_v3/data/raw/sql2/pan_continuous/pan_continuous.sql")
data
data <- readLines("/Users/glane/Dropbox/Matatu_v3/data/raw/sql2/pan_continuous/pan_continuous.txt")
head(data)
?readLines
data <- read.table("/Users/glane/Dropbox/Matatu_v3/data/raw/sql2/pan_continuous/pan_continuous.txt", sep=",")
head(data)
#assign names per the sql file that accompanies the .txt file
names(data) <- c("date","sense_record_id","participant_id","speed","bearing","ac_f","ac_r",
"ac_l","lat","lon","treat","ac_v","accel_alarm","speeding_alarm","sharp_turn_alarm",
"decel_alarm","acc_v_avg","acc_v_max","jerk_v_avg","jerk_v_max",
"acc_l_avg","acc_l_max","jerk_l_avg","jerk_l_max","acc_r_avg","acc_r_max",
"acc_f_avg","acc_f_max","jerk_fr_avg","jerk_fr_max")
head(datga)
head(data)
summary(ac_f)
summary(data$ac_f)
tail(data)
data <- data.frame(lapply(data, function(x) {
gsub("\\N", "NULL", x)
}))
head(data)
data <- read.table("/Users/glane/Dropbox/Matatu_v3/data/raw/sql2/pan_continuous/pan_continuous.txt", sep=",")
#assign names per the sql file that accompanies the .txt file
names(data) <- c("date","sense_record_id","participant_id","speed","bearing","ac_f","ac_r",
"ac_l","lat","lon","treat","ac_v","accel_alarm","speeding_alarm","sharp_turn_alarm",
"decel_alarm","acc_v_avg","acc_v_max","jerk_v_avg","jerk_v_max",
"acc_l_avg","acc_l_max","jerk_l_avg","jerk_l_max","acc_r_avg","acc_r_max",
"acc_f_avg","acc_f_max","jerk_fr_avg","jerk_fr_max")
temp <- head(data)
temp <- data.frame(lapply(temp, function(x) {
gsub("\\\\N", "NULL", x)
}))
View(temp)
p_load(ggplot2, ggthemes, viridis, plotly, stringr, lubridate, readr, data.table, dplyr, magrittr)
library(pacman)
p_load(ggplot2, ggthemes, viridis, plotly, stringr, lubridate, readr, data.table, dplyr, magrittr)
data <- data.frame(lapply(data, function(x) {
gsub("\\\\N", "NULL", x)
}))
write_csv(data, "/Users/glane/Dropbox/Matatu_v3/data/raw/sql/pan_continuous2.csv")
head(Data)
head(data)
rm(data)
data_daily <- read.table("/Users/glane/Dropbox/Matatu_v3/data/raw/sql2/pan_daily/pan_daily.txt", sep=",")
names(data_daily) <- c("participant_id", "treat", "date","mileage","deviceon","work_secs",
"avgspeed","maxspeed","stdspeed","overspeed","brake","overaccel",
"turn","apicalls","apihours","apivehicledashboard","alarmeventcalls","historymapcalls",
"historysummcalls","safesetspeedpush","safesetaccelpush","safesetbrakepush",
"prodsetignpush","prodsetarrpush","safesetspeedfeed","safesetaccelfeed",
"safesetbrakefeed","prodsetignfeed","prodsetarrfeed","owner_nsv","onroad",
"target","income","repaircost","repair","accident","impounded",
"fired","driver_change","driver_perf","driver_nsv","drive",
"revenue","salary","expenses","dayoff","separated","driverfired",
"othernotdriving","drivercalled","row_edited","row_edited_narr",
"row_edited_initials","routeleft","accident_verified",
"expenses_other","out_of_nbo","expenses_fuel","expenses_repairs",
"repaircost_o","a_it","a_it_speed","a_it_accel","a_it_brake",
"a_it_turn")
head(data_daily)
data_daily <- data.frame(lapply(data_daily, function(x) {
gsub("\\\\N", "NULL", x)
}))
write_csv(data_daily, "/Users/glane/Dropbox/Matatu_v3/data/raw/sql/pan_daily2.csv")
data_par <- read.table("/Users/glane/Dropbox/Matatu_v3/data/raw/sql2/participant/participant.txt", sep=",")
rm(data_daily)
names(data_par) <- c("regnum","mat_sensor_id","sense_uid","sense_created","name","phone","driver_phone",
"rct_group","treat","manager","phase","install","exit","exit_notes","route","misc_notes",
"prior_mat_sensor_id","cash_treat","cash_incentive_start","cash_treat_mos","cash_incentive_end",
"cash_followup","cash_start_1","cash_end_1")
data_par <- data.frame(lapply(data_par, function(x) {
gsub("\\\\N", "NULL", x)
}))
write_csv(data_par, "/Users/glane/Dropbox/Matatu_v3/data/raw/sql/participant2.csv")
shell("split -l 1000000 /Users/glane/Dropbox/Berkeley/Research/job_portals_continued/data/20200605_janjune/candidate_2020data/split_match/CandidateMatch_1-1-2020_to_june-2020.json")
# Description ------------------------------------------------------------------
#   GOAL: Read in the new candidate data sent by shine over the full 2019 year
#   and produce usable data set.
#   INITIAL AUTHOR: Greg
#   DATE STARTED: 25 June 2020
#   MOST RECENT AUTHOR: Greg
# Setup ------------------------------------------------------------------------
rm(list=ls())
# Options
options(stringsAsFactors = F)
library(pacman)
p_load(ggplot2, ggthemes, viridis, plotly, stringr, lubridate, readr, data.table, dplyr, magrittr,
jsonlite, purrr)
# File paths depending on the computer
if(Sys.info()["user"] == "erinmkelley") {
setwd("~/Dropbox/Berkeley 2017-2018/Research/job_portals_continued/data/")
dir <- "~/Dropbox/Berkeley 2017-2018/Research/job_portals_continued/data/"
}
if(Sys.info()["user"] == "gregorylane") {
setwd("~/Dropbox/Berkeley/Research/job_portals_continued/data/")
dir <- "~/Dropbox/Berkeley/Research/job_portals_continued/data/"
}
if(Sys.info()["user"] == "gregory.lane" | Sys.info()["user"] == "glane") {
setwd("~/Dropbox/Berkeley/Research/job_portals_continued/data/")
dir <- "~/Dropbox/Berkeley/Research/job_portals_continued/data/"
}
# Read in the lookup files - which will give us table values ---------------------------------------
# List all files in the Lookup files
files <- list.files("data_described/Lookups")
# Read these lookup files in
read.lookups <- function(df) {
df <- read.csv(paste0(dir,"data_described/Lookups/",df))
}
# Run the loop and assign each element of the list
set.lookups <- lapply(X = files, FUN = read.lookups)
names(set.lookups) <- str_replace(files, ".csv", "")
# Split the list up into separate data files for each lookup
list2env(set.lookups, envir = .GlobalEnv)
remove(set.lookups, read.lookups,files)
# Create labels for look-up data sets for merge
LookupExperience %<>% rename(label_exp = d) %>% select(-X_id)
LookupSkill %<>% rename(label_skill = sd) %>% select(si, label_skill)
LookupShiftType %<>% rename(label_shift = tv) %>% select(si, label_shift)
LookupCity %<>% rename(label_city_pref = cd) %>% select(ci, label_city_pref)
LookupSubFunctionalArea %<>% rename(label_function = sfe) %>% select(sfi, label_function)
LookupJobType %<>% rename(label_job_type = d) %>% select(v, label_job_type)
LookupAnnualSalary %<>% rename(label_pref_salary = tv, label_cur_salary = tvh) %>% select(si, label_pref_salary, label_cur_salary)
LookupCompany_14Aug %<>% select(-X_id) %>% rename(label_company = d)
LookupIndustry %<>% rename(label_industry = idesc) %>% select(ii, label_industry)
LookupJobTitle_new %<>% rename(label_title = jtd) %>% select(-X_id)
LookupEducationQualificationLevel2_Nu %<>% rename(label_educ = tv) %>% select(-X_id, -so)
LookupEducationStream_Nu %<>% rename(label_educ_area = sd) %>% select(si, label_educ_area) %>% unique()
LookupCourseType %<>% rename(label_course_type = d) %>% select(-X_id)
LookupEducationInstitute_Nu %<>% rename(label_institute = asd, label_instit_type = astd) %>% select(-X_id, -asti)
LookupTeamSizeManaged %<>% select(-X_id) %>% rename(team_size_label = tv)
files_match <- list.files("20200605_janjune/candidate_2020data/split_match")
files_match2 <- as.data.frame(cbind(files_match, 1:length(files_match)))
View(files_match2)
View(files_match2)
process_file <- files_static[1:length(files_match)]
process_file <- files_match[1:length(files_match)]
iteration <- files_match2 %>% filter(files_match==file) %>% select(V2) %>% as.character()
file <- files_match[1]
iteration <- files_match2 %>% filter(files_match==file) %>% select(V2) %>% as.character()
temp <- lapply(readLines(paste0("20200605_janjune/candidate_2020data/split_match/", file)), fromJSON)
df_candidate_match <- temp %>% map_dfr(~as.data.frame(t(unlist(x =.x))))
rm(temp)
head(df_candidate_match)
df_candidate_match %<>%
# these columns not used anymore (or are duplicates)
select(-fm, -ad, -a, -ds, -h) %>%
# order in a more userfriendly way
select(`_id.$oid`, fcu, fjj, md, aa, ri, e, vi, at, im)
setnames(df_candidate_match, c(
"can_id",
"can_id_2",
"job_id",
"app_date",
"auto_apply_choice",
"resume_id",
"resume_type",
"vendor_id",
"app_type",
"unkown"
))
head(df_candidate_match)
df_candidate_match %<>% select(-can_id)
rm(df_candidate_match)
can_match_fun <- function(file) {
iteration <- files_match2 %>% filter(files_match==file) %>% select(V2) %>% as.character()
temp <- lapply(readLines(paste0("20200605_janjune/candidate_2020data/split_match/", file)), fromJSON)
df_candidate_match <- temp %>% map_dfr(~as.data.frame(t(unlist(x =.x))))
rm(temp)
df_candidate_match %<>%
# these columns not used anymore (or are duplicates)
select(-fm, -ad, -a, -ds, -h) %>%
# order in a more userfriendly way
select(`_id.$oid`, fcu, fjj, md, aa, ri, e, vi, at, im)
setnames(df_candidate_match, c(
"can_id",
"can_id_2",
"job_id",
"app_date",
"auto_apply_choice",
"resume_id",
"resume_type",
"vendor_id",
"app_type",
"unkown"
))
df_candidate_match %<>% select(-can_id)
write_csv(df_candidate_match, paste0("modified/year_2020/candidates/can_match/can_match", iteration, ".csv"))
print(iteration)
rm(df_candidate_match)
}
process_file <- files_match[1:length(files_match)]
lapply(X = process_file, FUN = can_match_fun)
files_static <- list.files("20200605_janjune/candidate_2020data/split_static")
files_static2 <- as.data.frame(cbind(files_static, 1:length(files_static)))
can_static_fun <- function(file) {
iteration <- files_static2 %>% filter(files_static==file) %>% select(V2) %>% as.character()
temp <- lapply(readLines(paste0("20200605_janjune/candidate_2020data/split_static/", file)), fromJSON)
df_candidate_static <- temp %>% map_dfr(~as.data.frame(t(unlist(x =.x))))
rm(temp)
# it looks like the
df_candidate_static %<>% select(-starts_with("cfs"), -a, -starts_with("scp"),
-starts_with("uft"), -starts_with("et"))
#"cfs" - "certifications" variable is a problem, so getting rid of it - it has separate entry for each type of certification - overwhelms
# "a" is not used, "aui" not in description file, "uft" - update flow is uncessary
# "scp" - "Shine career plus" - flags we don't need, "et" - is not used
#Rename if ID is wong name
if(!exists(x="_id", where=df_candidate_static)){
df_candidate_static %<>% rename(`_id` = `_id.$oid`)
}
if(exists(x="_id", where=df_candidate_static) & exists(x="_id.$oid", where=df_candidate_static)){
df_candidate_static %<>% mutate(`_id`=ifelse(is.na(`_id`), `_id.$oid`, `_id`))
}
#if old Id still exists because both _id and -_id$oid were there, drop old ID
if(exists(x="_id.$oid", where=df_candidate_static)){
df_candidate_static %<>% select(-`_id.$oid`)
}
#mutate id columns to be numeric
df_candidate_static %<>% rename(can_id_2 = `_id`) %>% mutate(can_id_2 = unlist(can_id_2))
df_candidate_static %<>%
mutate_at(c("ex", "s", "tsm"), funs(as.numeric(str_replace_all(., "\\D", ""))))
#cull useless vars based on csv sheet
if(exists(x="eia", where=df_candidate_static)){
df_candidate_static %<>% select(-eia)
}
if(exists(x="sia", where=df_candidate_static)){
df_candidate_static %<>% select(-sia)
}
if(exists(x="aa", where=df_candidate_static)){
df_candidate_static %<>% select(-aa)
}
if(exists(x="qs", where=df_candidate_static)){
df_candidate_static %<>% select(-qs)
}
if(exists(x="rer", where=df_candidate_static)){
df_candidate_static %<>% select(-rer)
}
if(exists(x="drlu", where=df_candidate_static)){
df_candidate_static %<>% select(-drlu)
}
if(exists(x="p", where=df_candidate_static)){
df_candidate_static %<>% select(-p)
}
if(exists(x="m1r1", where=df_candidate_static)){
df_candidate_static %<>% select(-m1r1)
}
if(exists(x="m0r1", where=df_candidate_static)){
df_candidate_static %<>% select(-m0r1)
}
if(exists(x="m2r0", where=df_candidate_static)){
df_candidate_static %<>% select(-m2r0)
}
if(exists(x="m2r1", where=df_candidate_static)){
df_candidate_static %<>% select(-m2r1)
}
if(exists(x="mtw", where=df_candidate_static)){
df_candidate_static %<>% select(-mtw)
}
df_candidate_static %<>% select( -evi, -mo, -rm,
-rpi, -rsd, -saf, -svi, -acd,
-rvi, -lr, -pvd, -rstd, -npd, -rps, -mt,
-ut, -bw, -evd, -iad,
-ldt, -lxd, -ml, -rsr
)
#eia = end IP address, eq = not used, evi="end vendor id", mo=report for when user stopped registration
#mq=not used, p = password, qs = not used, rm = resume midout, rpi - "receive other prod info"
#saf = sms alert, sia = not used, svi=start vendor, drlu = resume flag, acd = not used
#rvi = revival vendor id, lr = last revival date, pvd = phone varification date,
#mt = mobile authorization code, rer = registration refferer, npl= notice period working
#ut = user old website, bw=bad words, ml = not used, aa= admin access,
#rsr = registration url, evd=not clear what is, not used often,
#m0r1 & m2r0 & etc. = not clear, but not used often, ldt=unclear, not used often, lxd=unclear, not used often
#ml-mobile lead, not used, mtw=unclear, not used, rsr=url link, big, remove
#merge in values for lookup files (experience and old salary and team size)
df_candidate_static <- merge(df_candidate_static, LookupExperience, by.x = "ex", by.y="v", all.x=TRUE)
LookupAnnualSalary2 <- LookupAnnualSalary %>% select(-label_pref_salary)
df_candidate_static <- merge(df_candidate_static, LookupAnnualSalary2, by.x = "s", by.y="si", all.x=TRUE)
df_candidate_static <- merge(df_candidate_static, LookupTeamSizeManaged, by.x = "tsm", by.y="rli", all.x=TRUE)
#filter out non-job seekers - variable JS is TRUE for job-seekrs, other are some other accounts
if(exists(x="js", where=df_candidate_static)){
df_candidate_static %<>% filter(js=="TRUE") %>%
select(-js)
}
#rename
df_candidate_static %<>%
rename(email_bounce_date = bod,
can_location = cl,
cell_num_verified = cpv,
email_setting = eas,
last_exp_mod = em,
email_verified = ev,
exper_code = ex,
exper_months = exm,
gender = g, #male=1, female=2
last_applied_date = lad,
last_login = ll,
last_mod = lm,
notice_period = np,
privacy_status = ps,
last_mod_pref = pu,
registration_date = red,
resume_title= rst,
old_salary_code = s,
salary_lakh = sl,
salary_thsd = st,
team_size_manage_code = tsm, #lookup code
tot_exp_mod = yeu,
birth_date = dob,
resume_post_code = rp,
salary_mod_date = slm,
#ed = ed, #no info on what this is
#er = er, #no info on what this is
postal_code = pc,
#lws = lws, #no info on what this is
last_loc_mod = lom,
#ldt = ldt, #no info on what this is
#lxd = lxd, #no info on what this is
junk_profile = jp,
email_bounce = bs,
spam_profile = ss,
dup_cell = idcp,
show_linkedin = slp,
soft_email_bounce = sb,
#lt = lt, #no info on what this is
last_work_date = npl)
#cp_j = cp_j, #noinfo on what this is
#jpd = jpd) #no info on what this is
#job_seeker = js)#,
#can_id_2 = can_id) #keep as can_id_2 to match with other files
#fix lists and also add in missed merge
df_candidate_static %<>%
mutate_at(c("can_location", "email_setting", "exper_months", "privacy_status"
), funs(as.numeric(str_replace_all(., "\\D", ""))))
LookupCity2 <- LookupCity %>% rename(label_can_loc = label_city_pref)
df_candidate_static <- merge(df_candidate_static, LookupCity2, by.x = "can_location", by.y="ci", all.x=TRUE)
# Export data frames as csv
write_csv(df_candidate_static, paste0("modified/year_2020/candidates/can_stat/can_static", iteration, ".csv"))
print(iteration)
rm(df_candidate_static)
}
process_file <- files_static[23:length(files_static)]
lapply(X = process_file, FUN = can_static_fun)
process_file <- files_static[24:length(files_static)]
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
setwd("~/Documents/Website/gregorylane.github.io")
rmarkdown::render_site()
